{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce9f70a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing 20131018...\n",
      "Processing transit data for date: 20131018\n",
      "1. Loading GTFS data...\n",
      "2. Loading existing processed data...\n",
      "3. Building service date mappings...\n",
      "4. Processing routes...\n",
      "No duplicate route_id found in routes_df.\n",
      "5. Processing route versions...\n",
      "6. Processing shape variants...\n",
      "Removed 7629 duplicate rows where only exception_type differed (NaN vs non-NaN).\n",
      "Updated shape_variants_df:\n",
      "Shape: (1544, 6)\n",
      "\n",
      "Updated shape_variant_activations_df:\n",
      "Shape: (61329, 3)\n",
      "\n",
      "Summary:\n",
      "Total unique shape variants: 1544\n",
      "Total shape variant activations: 61329\n",
      "New variants added: 49\n",
      "Shape variant IDs added: 101495 - 101543\n",
      "New activations added: 1747\n",
      "7. Saving processed data...\n",
      "routes_df saved to ../data/processed/routes.csv\n",
      "route_versions_df saved to ../data/processed/route_versions.csv\n",
      "shape_variants_df saved to ../data/processed/shape_variants.csv\n",
      "shape_variant_activations_df saved to ../data/processed/shape_variant_activations.csv\n",
      "Processing completed successfully!\n",
      "\n",
      "Processing 20131021...\n",
      "Processing transit data for date: 20131021\n",
      "1. Loading GTFS data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Documents\\Projects\\budapest_time_travel\\src\\data_processing\\data_loader.py:25: DtypeWarning: Columns (0,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  trips_df = pd.read_csv(trips_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. Loading existing processed data...\n",
      "3. Building service date mappings...\n",
      "4. Processing routes...\n",
      "No duplicate route_id found in routes_df.\n",
      "5. Processing route versions...\n",
      "6. Processing shape variants...\n",
      "Removed 8899 duplicate rows where only exception_type differed (NaN vs non-NaN).\n",
      "Updated shape_variants_df:\n",
      "Shape: (1580, 6)\n",
      "\n",
      "Updated shape_variant_activations_df:\n",
      "Shape: (62380, 3)\n",
      "\n",
      "Summary:\n",
      "Total unique shape variants: 1580\n",
      "Total shape variant activations: 62380\n",
      "New variants added: 36\n",
      "Shape variant IDs added: 101544 - 101579\n",
      "New activations added: 1051\n",
      "7. Saving processed data...\n",
      "routes_df saved to ../data/processed/routes.csv\n",
      "route_versions_df saved to ../data/processed/route_versions.csv\n",
      "shape_variants_df saved to ../data/processed/shape_variants.csv\n",
      "shape_variant_activations_df saved to ../data/processed/shape_variant_activations.csv\n",
      "Processing completed successfully!\n",
      "\n",
      "Processing 20131025...\n",
      "Processing transit data for date: 20131025\n",
      "1. Loading GTFS data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Documents\\Projects\\budapest_time_travel\\src\\data_processing\\data_loader.py:25: DtypeWarning: Columns (0,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  trips_df = pd.read_csv(trips_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. Loading existing processed data...\n",
      "3. Building service date mappings...\n",
      "4. Processing routes...\n",
      "No duplicate route_id found in routes_df.\n",
      "5. Processing route versions...\n",
      "6. Processing shape variants...\n",
      "Removed 10729 duplicate rows where only exception_type differed (NaN vs non-NaN).\n",
      "Updated shape_variants_df:\n",
      "Shape: (1606, 6)\n",
      "\n",
      "Updated shape_variant_activations_df:\n",
      "Shape: (63494, 3)\n",
      "\n",
      "Summary:\n",
      "Total unique shape variants: 1606\n",
      "Total shape variant activations: 63494\n",
      "New variants added: 26\n",
      "Shape variant IDs added: 101580 - 101605\n",
      "New activations added: 1114\n",
      "7. Saving processed data...\n",
      "routes_df saved to ../data/processed/routes.csv\n",
      "route_versions_df saved to ../data/processed/route_versions.csv\n",
      "shape_variants_df saved to ../data/processed/shape_variants.csv\n",
      "shape_variant_activations_df saved to ../data/processed/shape_variant_activations.csv\n",
      "Processing completed successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Documents\\Projects\\budapest_time_travel\\src\\data_processing\\data_loader.py:25: DtypeWarning: Columns (0,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  trips_df = pd.read_csv(trips_path)\n"
     ]
    }
   ],
   "source": [
    "# Updated notebook using the new modular structure\n",
    "# preprocessing_v10.ipynb\n",
    "\n",
    "# Cell 1: Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Set path - adjust according to your new package location\n",
    "project_root = os.path.abspath(os.path.join(\"..\", \"src\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# Import the new modular package\n",
    "from data_processor import process_transit_data, TransitDataProcessor, FlexibleDateProcessor\n",
    "\n",
    "# # Cell 2: Simple processing using the convenience function\n",
    "# date = '20131018'\n",
    "data_folder = '../data/processed/'\n",
    "\n",
    "# # Process the data - this replaces all the individual function calls\n",
    "# result = process_transit_data(date, data_folder, save_data=True)\n",
    "\n",
    "# # Cell 3: Access the results if needed for further analysis\n",
    "# shapes_df = result['shapes']\n",
    "# routes_df = result['routes']\n",
    "# route_versions_df = result['route_versions']\n",
    "# shape_variants_df = result['shape_variants']\n",
    "# shape_variant_activations_df = result['shape_variant_activations']\n",
    "# temporary_changes_df = result['temporary_changes']\n",
    "\n",
    "# print(f\"Routes: {routes_df.shape}\")\n",
    "# print(f\"Route versions: {route_versions_df.shape}\")\n",
    "# print(f\"Shape variants: {shape_variants_df.shape}\")\n",
    "# print(f\"Shape variant activations: {shape_variant_activations_df.shape}\")\n",
    "\n",
    "# Cell 4: Alternative - using the class for more control\n",
    "processor = TransitDataProcessor(data_folder)\n",
    "\n",
    "# # Process without saving (for testing)\n",
    "# result = processor.process_date(date, save_data=False)\n",
    "\n",
    "# Or process multiple dates in a loop\n",
    "dates_to_process = ['20131018', '20131021', '20131025']\n",
    "for date in dates_to_process:\n",
    "    print(f\"\\nProcessing {date}...\")\n",
    "    processor.process_date(date, save_data=True)\n",
    "\n",
    "# Cell 5: Individual function usage (if you need more granular control)\n",
    "from data_processor import (\n",
    "    load_gtfs_data, load_processed_data, \n",
    "    build_service_date_mappings, build_latest_routes\n",
    ")\n",
    "\n",
    "# Load data manually\n",
    "routes_txt, trips_txt, shapes_txt, calendar_txt, calendar_dates_txt = load_gtfs_data(date)\n",
    "processed_data = load_processed_data(data_folder)\n",
    "\n",
    "# Build mappings\n",
    "trip_dates, trip_first_date = build_service_date_mappings(trips_txt, calendar_txt)\n",
    "\n",
    "# Continue with individual processing steps as needed..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599a3d5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa2a2f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Set path - adjust according to your new package location\n",
    "project_root = os.path.abspath(os.path.join(\"..\", \"src\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4e4d0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 22 date(s): 20131010 to 20131031\n",
      "Processing 20131010 (1/22)... ✗ ([Errno 2] No such file or directory: '../data/raw/...)\n",
      "Processing 20131011 (2/22)... ✗ ([Errno 2] No such file or directory: '../data/raw/...)\n",
      "Processing 20131012 (3/22)... ✗ ([Errno 2] No such file or directory: '../data/raw/...)\n",
      "Processing 20131013 (4/22)... ✗ ([Errno 2] No such file or directory: '../data/raw/...)\n",
      "Processing 20131014 (5/22)... ✗ ([Errno 2] No such file or directory: '../data/raw/...)\n",
      "Processing 20131015 (6/22)... ✗ ([Errno 2] No such file or directory: '../data/raw/...)\n",
      "Processing 20131016 (7/22)... ✗ ([Errno 2] No such file or directory: '../data/raw/...)\n",
      "Processing 20131017 (8/22)... ✗ ([Errno 2] No such file or directory: '../data/raw/...)\n",
      "Processing 20131018 (9/22)... ✓\n",
      "Processing 20131019 (10/22)... ✗ ([Errno 2] No such file or directory: '../data/raw/...)\n",
      "Processing 20131020 (11/22)... ✗ ([Errno 2] No such file or directory: '../data/raw/...)\n",
      "Processing 20131021 (12/22)... ✓\n",
      "Processing 20131022 (13/22)... ✗ ([Errno 2] No such file or directory: '../data/raw/...)\n",
      "Processing 20131023 (14/22)... ✗ ([Errno 2] No such file or directory: '../data/raw/...)\n",
      "Processing 20131024 (15/22)... ✗ ([Errno 2] No such file or directory: '../data/raw/...)\n",
      "Processing 20131025 (16/22)... ✓\n",
      "Processing 20131026 (17/22)... ✗ ([Errno 2] No such file or directory: '../data/raw/...)\n",
      "Processing 20131027 (18/22)... ✗ ([Errno 2] No such file or directory: '../data/raw/...)\n",
      "Processing 20131028 (19/22)... ✗ ([Errno 2] No such file or directory: '../data/raw/...)\n",
      "Processing 20131029 (20/22)... ✗ ([Errno 2] No such file or directory: '../data/raw/...)\n",
      "Processing 20131030 (21/22)... ✗ ([Errno 2] No such file or directory: '../data/raw/...)\n",
      "Processing 20131031 (22/22)... ✗ ([Errno 2] No such file or directory: '../data/raw/...)\n"
     ]
    }
   ],
   "source": [
    "from data_processor import FlexibleDateProcessor\n",
    "processor = FlexibleDateProcessor('../data/processed/')\n",
    "\n",
    "# Process a specific month\n",
    "processing_result = processor.process_dates({'start': '20131010', 'end': '20131031'}, progress=\"compact\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f964c689",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "budapest_tt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
