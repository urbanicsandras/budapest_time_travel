{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce9f70a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing 20131018...\n",
      "Processing transit data for date: 20131018\n",
      "1. Loading GTFS data...\n",
      "2. Loading existing processed data...\n",
      "3. Building service date mappings...\n",
      "4. Processing routes...\n",
      "No duplicate route_id found in routes_df.\n",
      "5. Processing route versions...\n",
      "6. Processing shape variants...\n",
      "Removed 7629 duplicate rows where only exception_type differed (NaN vs non-NaN).\n",
      "Updated shape_variants_df:\n",
      "Shape: (1544, 6)\n",
      "\n",
      "Updated shape_variant_activations_df:\n",
      "Shape: (61329, 3)\n",
      "\n",
      "Summary:\n",
      "Total unique shape variants: 1544\n",
      "Total shape variant activations: 61329\n",
      "New variants added: 49\n",
      "Shape variant IDs added: 101495 - 101543\n",
      "New activations added: 1747\n",
      "7. Saving processed data...\n",
      "routes_df saved to ../data/processed/routes.csv\n",
      "route_versions_df saved to ../data/processed/route_versions.csv\n",
      "shape_variants_df saved to ../data/processed/shape_variants.csv\n",
      "shape_variant_activations_df saved to ../data/processed/shape_variant_activations.csv\n",
      "Processing completed successfully!\n",
      "\n",
      "Processing 20131021...\n",
      "Processing transit data for date: 20131021\n",
      "1. Loading GTFS data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Documents\\Projects\\budapest_time_travel\\src\\data_processing\\data_loader.py:25: DtypeWarning: Columns (0,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  trips_df = pd.read_csv(trips_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. Loading existing processed data...\n",
      "3. Building service date mappings...\n",
      "4. Processing routes...\n",
      "No duplicate route_id found in routes_df.\n",
      "5. Processing route versions...\n",
      "6. Processing shape variants...\n",
      "Removed 8899 duplicate rows where only exception_type differed (NaN vs non-NaN).\n",
      "Updated shape_variants_df:\n",
      "Shape: (1580, 6)\n",
      "\n",
      "Updated shape_variant_activations_df:\n",
      "Shape: (62380, 3)\n",
      "\n",
      "Summary:\n",
      "Total unique shape variants: 1580\n",
      "Total shape variant activations: 62380\n",
      "New variants added: 36\n",
      "Shape variant IDs added: 101544 - 101579\n",
      "New activations added: 1051\n",
      "7. Saving processed data...\n",
      "routes_df saved to ../data/processed/routes.csv\n",
      "route_versions_df saved to ../data/processed/route_versions.csv\n",
      "shape_variants_df saved to ../data/processed/shape_variants.csv\n",
      "shape_variant_activations_df saved to ../data/processed/shape_variant_activations.csv\n",
      "Processing completed successfully!\n",
      "\n",
      "Processing 20131025...\n",
      "Processing transit data for date: 20131025\n",
      "1. Loading GTFS data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Documents\\Projects\\budapest_time_travel\\src\\data_processing\\data_loader.py:25: DtypeWarning: Columns (0,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  trips_df = pd.read_csv(trips_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. Loading existing processed data...\n",
      "3. Building service date mappings...\n",
      "4. Processing routes...\n",
      "No duplicate route_id found in routes_df.\n",
      "5. Processing route versions...\n",
      "6. Processing shape variants...\n",
      "Removed 10729 duplicate rows where only exception_type differed (NaN vs non-NaN).\n",
      "Updated shape_variants_df:\n",
      "Shape: (1606, 6)\n",
      "\n",
      "Updated shape_variant_activations_df:\n",
      "Shape: (63494, 3)\n",
      "\n",
      "Summary:\n",
      "Total unique shape variants: 1606\n",
      "Total shape variant activations: 63494\n",
      "New variants added: 26\n",
      "Shape variant IDs added: 101580 - 101605\n",
      "New activations added: 1114\n",
      "7. Saving processed data...\n",
      "routes_df saved to ../data/processed/routes.csv\n",
      "route_versions_df saved to ../data/processed/route_versions.csv\n",
      "shape_variants_df saved to ../data/processed/shape_variants.csv\n",
      "shape_variant_activations_df saved to ../data/processed/shape_variant_activations.csv\n",
      "Processing completed successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Documents\\Projects\\budapest_time_travel\\src\\data_processing\\data_loader.py:25: DtypeWarning: Columns (0,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  trips_df = pd.read_csv(trips_path)\n"
     ]
    }
   ],
   "source": [
    "# Updated notebook using the new modular structure\n",
    "# preprocessing_v10.ipynb\n",
    "\n",
    "# Cell 1: Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Set path - adjust according to your new package location\n",
    "project_root = os.path.abspath(os.path.join(\"..\", \"src\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# Import the new modular package\n",
    "from data_processor import process_transit_data, TransitDataProcessor, FlexibleDateProcessor\n",
    "\n",
    "# # Cell 2: Simple processing using the convenience function\n",
    "# date = '20131018'\n",
    "data_folder = '../data/processed/'\n",
    "\n",
    "# # Process the data - this replaces all the individual function calls\n",
    "# result = process_transit_data(date, data_folder, save_data=True)\n",
    "\n",
    "# # Cell 3: Access the results if needed for further analysis\n",
    "# shapes_df = result['shapes']\n",
    "# routes_df = result['routes']\n",
    "# route_versions_df = result['route_versions']\n",
    "# shape_variants_df = result['shape_variants']\n",
    "# shape_variant_activations_df = result['shape_variant_activations']\n",
    "# temporary_changes_df = result['temporary_changes']\n",
    "\n",
    "# print(f\"Routes: {routes_df.shape}\")\n",
    "# print(f\"Route versions: {route_versions_df.shape}\")\n",
    "# print(f\"Shape variants: {shape_variants_df.shape}\")\n",
    "# print(f\"Shape variant activations: {shape_variant_activations_df.shape}\")\n",
    "\n",
    "# Cell 4: Alternative - using the class for more control\n",
    "processor = TransitDataProcessor(data_folder)\n",
    "\n",
    "# # Process without saving (for testing)\n",
    "# result = processor.process_date(date, save_data=False)\n",
    "\n",
    "# Or process multiple dates in a loop\n",
    "dates_to_process = ['20131018', '20131021', '20131025']\n",
    "for date in dates_to_process:\n",
    "    print(f\"\\nProcessing {date}...\")\n",
    "    processor.process_date(date, save_data=True)\n",
    "\n",
    "# Cell 5: Individual function usage (if you need more granular control)\n",
    "from data_processor import (\n",
    "    load_gtfs_data, load_processed_data, \n",
    "    build_service_date_mappings, build_latest_routes\n",
    ")\n",
    "\n",
    "# Load data manually\n",
    "routes_txt, trips_txt, shapes_txt, calendar_txt, calendar_dates_txt = load_gtfs_data(date)\n",
    "processed_data = load_processed_data(data_folder)\n",
    "\n",
    "# Build mappings\n",
    "trip_dates, trip_first_date = build_service_date_mappings(trips_txt, calendar_txt)\n",
    "\n",
    "# Continue with individual processing steps as needed..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599a3d5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa2a2f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Set path - adjust according to your new package location\n",
    "project_root = os.path.abspath(os.path.join(\"..\", \"src\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4e4d0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 31 date(s): 20131001 to 20131031\n",
      "\n",
      "--- Processing 20131001 (1/31) ---\n",
      "Processing transit data for date: 20131001\n",
      "1. Loading GTFS data...\n",
      "✗ Failed to process 20131001: [Errno 2] No such file or directory: '../data/raw/20131001\\\\routes.txt'\n",
      "\n",
      "--- Processing 20131002 (2/31) ---\n",
      "Processing transit data for date: 20131002\n",
      "1. Loading GTFS data...\n",
      "✗ Failed to process 20131002: [Errno 2] No such file or directory: '../data/raw/20131002\\\\routes.txt'\n",
      "\n",
      "--- Processing 20131003 (3/31) ---\n",
      "Processing transit data for date: 20131003\n",
      "1. Loading GTFS data...\n",
      "✗ Failed to process 20131003: [Errno 2] No such file or directory: '../data/raw/20131003\\\\routes.txt'\n",
      "\n",
      "--- Processing 20131004 (4/31) ---\n",
      "Processing transit data for date: 20131004\n",
      "1. Loading GTFS data...\n",
      "✗ Failed to process 20131004: [Errno 2] No such file or directory: '../data/raw/20131004\\\\routes.txt'\n",
      "\n",
      "--- Processing 20131005 (5/31) ---\n",
      "Processing transit data for date: 20131005\n",
      "1. Loading GTFS data...\n",
      "✗ Failed to process 20131005: [Errno 2] No such file or directory: '../data/raw/20131005\\\\routes.txt'\n",
      "\n",
      "--- Processing 20131006 (6/31) ---\n",
      "Processing transit data for date: 20131006\n",
      "1. Loading GTFS data...\n",
      "✗ Failed to process 20131006: [Errno 2] No such file or directory: '../data/raw/20131006\\\\routes.txt'\n",
      "\n",
      "--- Processing 20131007 (7/31) ---\n",
      "Processing transit data for date: 20131007\n",
      "1. Loading GTFS data...\n",
      "✗ Failed to process 20131007: [Errno 2] No such file or directory: '../data/raw/20131007\\\\routes.txt'\n",
      "\n",
      "--- Processing 20131008 (8/31) ---\n",
      "Processing transit data for date: 20131008\n",
      "1. Loading GTFS data...\n",
      "✗ Failed to process 20131008: [Errno 2] No such file or directory: '../data/raw/20131008\\\\routes.txt'\n",
      "\n",
      "--- Processing 20131009 (9/31) ---\n",
      "Processing transit data for date: 20131009\n",
      "1. Loading GTFS data...\n",
      "✗ Failed to process 20131009: [Errno 2] No such file or directory: '../data/raw/20131009\\\\routes.txt'\n",
      "\n",
      "--- Processing 20131010 (10/31) ---\n",
      "Processing transit data for date: 20131010\n",
      "1. Loading GTFS data...\n",
      "✗ Failed to process 20131010: [Errno 2] No such file or directory: '../data/raw/20131010\\\\routes.txt'\n",
      "\n",
      "--- Processing 20131011 (11/31) ---\n",
      "Processing transit data for date: 20131011\n",
      "1. Loading GTFS data...\n",
      "✗ Failed to process 20131011: [Errno 2] No such file or directory: '../data/raw/20131011\\\\routes.txt'\n",
      "\n",
      "--- Processing 20131012 (12/31) ---\n",
      "Processing transit data for date: 20131012\n",
      "1. Loading GTFS data...\n",
      "✗ Failed to process 20131012: [Errno 2] No such file or directory: '../data/raw/20131012\\\\routes.txt'\n",
      "\n",
      "--- Processing 20131013 (13/31) ---\n",
      "Processing transit data for date: 20131013\n",
      "1. Loading GTFS data...\n",
      "✗ Failed to process 20131013: [Errno 2] No such file or directory: '../data/raw/20131013\\\\routes.txt'\n",
      "\n",
      "--- Processing 20131014 (14/31) ---\n",
      "Processing transit data for date: 20131014\n",
      "1. Loading GTFS data...\n",
      "✗ Failed to process 20131014: [Errno 2] No such file or directory: '../data/raw/20131014\\\\routes.txt'\n",
      "\n",
      "--- Processing 20131015 (15/31) ---\n",
      "Processing transit data for date: 20131015\n",
      "1. Loading GTFS data...\n",
      "✗ Failed to process 20131015: [Errno 2] No such file or directory: '../data/raw/20131015\\\\routes.txt'\n",
      "\n",
      "--- Processing 20131016 (16/31) ---\n",
      "Processing transit data for date: 20131016\n",
      "1. Loading GTFS data...\n",
      "✗ Failed to process 20131016: [Errno 2] No such file or directory: '../data/raw/20131016\\\\routes.txt'\n",
      "\n",
      "--- Processing 20131017 (17/31) ---\n",
      "Processing transit data for date: 20131017\n",
      "1. Loading GTFS data...\n",
      "✗ Failed to process 20131017: [Errno 2] No such file or directory: '../data/raw/20131017\\\\routes.txt'\n",
      "\n",
      "--- Processing 20131018 (18/31) ---\n",
      "Processing transit data for date: 20131018\n",
      "1. Loading GTFS data...\n",
      "2. Loading existing processed data...\n",
      "Some processed data files not found. Creating empty dataframes.\n",
      "3. Building service date mappings...\n",
      "4. Processing routes...\n",
      "No duplicate route_id found in routes_df.\n",
      "5. Processing route versions...\n",
      "6. Processing shape variants...\n",
      "Removed 7629 duplicate rows where only exception_type differed (NaN vs non-NaN).\n",
      "return_df:  Index(['version_id', 'route_id', 'direction_id', 'is_main', 'shape_id',\n",
      "       'trip_headsign', 'date', 'exception_type'],\n",
      "      dtype='object')\n",
      "Updated shape_variants_df:\n",
      "Shape: (1151, 6)\n",
      "\n",
      "Updated shape_variant_activations_df:\n",
      "Shape: (38754, 3)\n",
      "\n",
      "Summary:\n",
      "Total unique shape variants: 1151\n",
      "Total shape variant activations: 38754\n",
      "New variants added: 1151\n",
      "Shape variant IDs added: 100000 - 101150\n",
      "New activations added: 38754\n",
      "7. Updating shapes data...\n",
      "\n",
      "=== Before update Shapes Summary ===\n",
      "Total shape records: 0\n",
      "Unique shapes: 0\n",
      "Found 1151 missing shape_ids that need to be added.\n",
      "Found 1151 missing shape_ids in shapes_df.\n",
      "Missing shape_ids: ['0028', '0030', '0145', '0154', '0155', '0249', '0266', '0285', '0448', '0449', '0506', '0538', '0540', '0575', '0576', '0583', '0584', '0714', '0715', '0729', '0730', '0741', '0781', '0802', '0803', '0976', '0977', '1019', '1020', '1109', '1110', '1111', '1112', '1113', '1114', '1135', '1174', '1176', '1203', '1204', '1205', '1206', '1207', '1208', '1225', '1226', '1227', '1228', '1229', '1230', '1233', '1245', '1246', '1513', '1769', '1957', '1986', '2032', '2061', '2064', '2065', '2066', '2140', '2148', '2226', '2227', '2232', '2246', '2247', '2248', '2249', '2265', '2266', '2267', '2268', '2269', '2270', '2273', '2375', '2380', '2381', '2384', '2490', '2491', '3158', '3159', '3801', '4100', '4439', '5145', '5146', '5184', '5231', '5233', '5568', '5572', '5911', '6133', '6136', '6137', '6138', '6790', '6791', '6832', '6833', '6863', '6914', '7504', 'A066', 'A067', 'A068', 'A083', 'A114', 'A115', 'A139', 'A155', 'A156', 'A178', 'A179', 'A180', 'A240', 'A243', 'A255', 'A256', 'A257', 'B042', 'B098', 'B099', 'B103', 'B104', 'B116', 'B117', 'B180', 'B185', 'B212', 'B213', 'B692', 'B693', 'B823', 'B824', 'B825', 'B957', 'B958', 'B964', 'B965', 'C026', 'C085', 'C086', 'C106', 'C123', 'C124', 'C139', 'C159', 'C182', 'C224', 'C552', 'C569', 'C570', 'C583', 'C584', 'C595', 'C597', 'C660', 'C709', 'C721', 'C723', 'C754', 'C755', 'D144', 'D146', 'D150', 'D151', 'D208', 'D209', 'D307', 'D366', 'D369', 'D370', 'D604', 'D605', 'D610', 'D611', 'D934', 'D960', 'E025', 'E040', 'E182', 'E183', 'E211', 'E306', 'E322', 'E757', 'E758', 'E769', 'E784', 'E796', 'E799', 'E819', 'E820', 'E824', 'E860', 'E861', 'E977', 'E978', 'G048', 'G049', 'G060', 'G097', 'G139', 'G140', 'G173', 'G174', 'G181', 'G182', 'G186', 'G187', 'G188', 'G189', 'G201', 'G319', 'G320', 'G367', 'G368', 'G371', 'G372', 'G373', 'G380', 'G389', 'G394', 'G395', 'G396', 'G397', 'G413', 'G414', 'G415', 'G419', 'G424', 'G425', 'G426', 'G429', 'G430', 'G431', 'G432', 'G433', 'G440', 'G441', 'G443', 'G446', 'G469', 'G470', 'G547', 'G556', 'G557', 'G558', 'G567', 'G571', 'G591', 'G602', 'G609', 'G697', 'G742', 'G747', 'G748', 'G749', 'G762', 'G767', 'G771', 'G844', 'G845', 'G848', 'G937', 'H075', 'H257', 'H265', 'H266', 'H302', 'H307', 'H320', 'H323', 'H324', 'H364', 'H424', 'H425', 'H428', 'H440', 'H441', 'H442', 'H443', 'H460', 'H461', 'H473', 'H474', 'H549', 'H583', 'H584', 'H588', 'H589', 'H590', 'H669', 'H939', 'H963', 'H988', 'H989', 'H990', 'I005', 'I032', 'I295', 'I296', 'I298', 'I366', 'I367', 'I368', 'I369', 'I666', 'I667', 'I668', 'I669', 'I674', 'I675', 'I836', 'I974', 'I976', 'I977', 'I999', 'J035', 'J036', 'J038', 'J039', 'J086', 'J087', 'J088', 'J089', 'J092', 'J105', 'J106', 'J107', 'J108', 'J336', 'J367', 'J369', 'J370', 'J371', 'J372', 'J373', 'J396', 'J407', 'J413', 'J418', 'J453', 'J456', 'J486', 'J520', 'J521', 'J522', 'J523', 'J528', 'J529', 'J597', 'J695', 'J698', 'J699', 'J798', 'J899', 'J900', 'J901', 'J902', 'J904', 'J906', 'K000', 'K001', 'K028', 'K029', 'K090', 'K091', 'K108', 'K638', 'K712', 'K779', 'K780', 'K873', 'K874', 'K902', 'L014', 'L015', 'L035', 'L044', 'L101', 'L119', 'L129', 'L130', 'L134', 'L135', 'L141', 'L177', 'L178', 'L179', 'L181', 'L182', 'L187', 'L188', 'L194', 'L635', 'L637', 'L638', 'L639', 'L640', 'L641', 'L650', 'L651', 'L652', 'L653', 'L654', 'L655', 'L656', 'L657', 'L658', 'L659', 'L661', 'L667', 'L668', 'L669', 'L670', 'L671', 'L672', 'L674', 'L675', 'L676', 'L677', 'L678', 'L679', 'L680', 'L681', 'L684', 'L685', 'L691', 'L695', 'L696', 'L712', 'L751', 'L752', 'L803', 'L804', 'L839', 'L864', 'L865', 'L967', 'L995', 'L997', 'L998', 'M005', 'M006', 'M010', 'M012', 'M021', 'M024', 'M025', 'M026', 'M027', 'M030', 'M031', 'M035', 'M036', 'M037', 'M041', 'M080', 'M086', 'M095', 'M099', 'M101', 'M103', 'M104', 'M105', 'M108', 'M115', 'M116', 'M117', 'M118', 'M124', 'M125', 'M127', 'M128', 'M129', 'M130', 'M132', 'M238', 'M239', 'M282', 'M283', 'M361', 'M364', 'M689', 'M709', 'M710', 'M760', 'M761', 'M762', 'M763', 'M768', 'M770', 'M775', 'M777', 'M858', 'M872', 'M882', 'M993', 'N016', 'N017', 'N023', 'N024', 'N360', 'N503', 'N504', 'N563', 'N644', 'N649', 'N650', 'N702', 'N711', 'N712', 'N713', 'N735', 'N736', 'N742', 'N743', 'N744', 'N745', 'N746', 'N756', 'N757', 'N762', 'N763', 'N766', 'N769', 'N770', 'N782', 'N783', 'N804', 'N806', 'N819', 'N820', 'N869', 'N870', 'N871', 'N872', 'N873', 'N877', 'N878', 'N879', 'N882', 'N883', 'N924', 'N932', 'N933', 'N934', 'N935', 'N936', 'N937', 'N950', 'N951', 'N952', 'N953', 'N956', 'N958', 'N959', 'N961', 'N962', 'N966', 'N967', 'N981', 'N982', 'N983', 'N984', 'O096', 'O218', 'O258', 'O259', 'O276', 'O277', 'O287', 'O318', 'O386', 'O389', 'O390', 'O393', 'O397', 'O398', 'O401', 'O496', 'O578', 'O579', 'O580', 'O582', 'O603', 'O604', 'O626', 'O627', 'O797', 'O798', 'O804', 'P540', 'P541', 'P542', 'P543', 'P547', 'P548', 'P549', 'P550', 'P551', 'P555', 'P624', 'P626', 'P630', 'P639', 'P640', 'P700', 'P701', 'P702', 'P709', 'P760', 'P780', 'P781', 'P815', 'P830', 'P853', 'P855', 'P856', 'P857', 'P858', 'P861', 'P862', 'P863', 'P864', 'P865', 'P866', 'P867', 'P868', 'P890', 'P891', 'P893', 'P900', 'P901', 'P923', 'P926', 'P927', 'Q350', 'Q354', 'Q449', 'Q450', 'Q456', 'Q457', 'Q478', 'Q480', 'Q505', 'Q506', 'Q512', 'Q518', 'Q546', 'Q547', 'Q592', 'Q594', 'Q596', 'Q597', 'Q598', 'Q599', 'Q600', 'Q601', 'Q602', 'Q605', 'Q606', 'Q690', 'Q691', 'Q719', 'Q741', 'Q745', 'Q755', 'Q756', 'Q757', 'Q768', 'Q790', 'Q806', 'Q823', 'Q828', 'Q829', 'Q830', 'Q888', 'R268', 'R305', 'R306', 'R308', 'R309', 'R310', 'R312', 'R313', 'R328', 'R408', 'R409', 'R463', 'R464', 'R489', 'R490', 'R511', 'R512', 'R515', 'R516', 'R518', 'R519', 'R555', 'R557', 'R688', 'R689', 'R691', 'R692', 'R694', 'R696', 'R704', 'R705', 'R706', 'R707', 'R708', 'R709', 'R710', 'R711', 'R723', 'R797', 'R798', 'R803', 'R804', 'R828', 'R829', 'R842', 'R843', 'R844', 'R845', 'R877', 'R878', 'R879', 'R880', 'R881', 'R882', 'R883', 'R899', 'R938', 'R939', 'R940', 'R941', 'R942', 'R943', 'R952', 'R985', 'S014', 'S015', 'S018', 'S020', 'S022', 'S026', 'S028', 'S045', 'S048', 'S051', 'S052', 'S071', 'S089', 'S091', 'S092', 'S093', 'S126', 'S136', 'S138', 'S141', 'S184', 'S186', 'S187', 'S188', 'S189', 'S190', 'S192', 'S193', 'S201', 'S203', 'S214', 'S215', 'S245', 'S246', 'S247', 'S248', 'S249', 'S293', 'S294', 'S296', 'S297', 'S322', 'S358', 'S359', 'S362', 'S363', 'S374', 'S375', 'S381', 'S382', 'S383', 'S384', 'S385', 'S386', 'S387', 'S395', 'S396', 'S397', 'S398', 'S399', 'S400', 'S402', 'S534', 'S578', 'S579', 'S580', 'S581', 'S625', 'S626', 'S627', 'S628', 'S629', 'S630', 'S631', 'S632', 'S633', 'S635', 'S640', 'S663', 'S666', 'S704', 'S705', 'S706', 'S707', 'S710', 'S711', 'S713', 'S724', 'S733', 'S806', 'S807', 'S853', 'S854', 'S860', 'S861', 'S867', 'S905', 'S962', 'S963', 'S997', 'S999', 'T001', 'T002', 'T003', 'T004', 'T008', 'T021', 'T031', 'T032', 'T035', 'T036', 'T037', 'T038', 'T040', 'T041', 'T051', 'T052', 'T317', 'T395', 'T409', 'T413', 'T414', 'T418', 'T506', 'T571', 'T572', 'T584', 'T651', 'T687', 'T688', 'T773', 'T774', 'T811', 'T812', 'T840', 'T847', 'T855', 'T862', 'T863', 'T866', 'T872', 'T879', 'T881', 'T883', 'T884', 'T894', 'T918', 'T920', 'T937', 'T967', 'U006', 'U007', 'U117', 'U142', 'U143', 'U144', 'U149', 'U150', 'U154', 'U155', 'U156', 'U157', 'U161', 'U162', 'U163', 'U171', 'U172', 'U197', 'U206', 'U207', 'U209', 'U210', 'U215', 'U216', 'U217', 'U218', 'U219', 'U220', 'U221', 'U230', 'U251', 'U252', 'U253', 'U254', 'U277', 'U326', 'U327', 'U328', 'U331', 'U332', 'U336', 'U337', 'U339', 'U340', 'U341', 'U372', 'U373', 'U482', 'U483', 'U486', 'U487', 'U488', 'U509', 'U510', 'U527', 'U528', 'U533', 'U534', 'U542', 'U551', 'U552', 'U553', 'U554', 'U555', 'U572', 'U626', 'U627', 'U703', 'U704', 'U711', 'U712', 'U719', 'U720', 'U723', 'U741', 'U742', 'U743', 'U749', 'U770', 'U771', 'U775', 'U780', 'U782', 'U783', 'U784', 'U785', 'U786', 'U787', 'U788', 'U790', 'U791', 'U795', 'U798', 'U800', 'U803', 'U804', 'U805', 'U806', 'U807', 'U808', 'U809', 'U813', 'U814', 'U815', 'U816', 'U818', 'U871', 'U915', 'U916', 'U921', 'U922', 'U951', 'U959', 'U960', 'U961', 'U971', 'U972', 'U974', 'U977', 'U995', 'V004', 'V014', 'V023', 'V024', 'V027', 'V029', 'V030', 'V031', 'V032', 'V033', 'V034', 'V038', 'V039', 'V040', 'V041', 'V046', 'V047', 'V048', 'V051', 'V052', 'V053', 'V055', 'V056', 'V126', 'V127', 'V129', 'V130', 'V131', 'V177', 'V181', 'V182', 'V184', 'V185', 'V233', 'V234', 'V308', 'V318', 'V319', 'V321', 'V343', 'V344', 'V360', 'V411', 'V412', 'V413', 'V414', 'V419', 'V420', 'V421', 'V422', 'V459', 'V735', 'V839', 'V840', 'V878', 'W263', 'W271', 'W272', 'W300', 'W308', 'W309', 'W310', 'W388', 'W389', 'W391', 'W392', 'W397', 'W398', 'W399', 'W405', 'W470', 'W481', 'W484', 'W485', 'W486', 'W487', 'W488', 'W489', 'W493', 'W649', 'W650', 'W678', 'W679', 'W680', 'W775', 'W801', 'W802', 'W954', 'W955', 'W987', 'W988', 'W993', 'W997', 'W998', 'X016', 'X017', 'X020', 'X021', 'X022', 'X023', 'X024', 'X032', 'X033', 'X034', 'X064', 'X066', 'X067', 'X068', 'X132', 'X133', 'X156', 'X162', 'X163', 'X197', 'X198', 'X199', 'X200', 'X202', 'X203', 'X206', 'X209', 'X217', 'X219', 'X221', 'X234', 'X377', 'X379', 'X380', 'X381', 'X382', 'X383', 'X386']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Documents\\Projects\\budapest_time_travel\\src\\data_processor\\shapes_updater.py:56: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  updated_shapes_df = pd.concat([shapes_df, missing_shapes], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 210973 shape records to shapes_df.\n",
      "New shapes_df shape: (210973, 6)\n",
      "\n",
      "=== After update Shapes Summary ===\n",
      "Total shape records: 210,973\n",
      "Unique shapes: 1,151\n",
      "Average points per shape: 183.3\n",
      "Points per shape range: 6 - 957\n",
      "8. Saving processed data...\n",
      "shapes_df saved to ../data/processed/shapes.csv\n",
      "routes_df saved to ../data/processed/routes.csv\n",
      "route_versions_df saved to ../data/processed/route_versions.csv\n",
      "shape_variants_df saved to ../data/processed/shape_variants.csv\n",
      "shape_variant_activations_df saved to ../data/processed/shape_variant_activations.csv\n",
      "Processing completed successfully!\n",
      "✓ Successfully processed 20131018\n",
      "\n",
      "--- Processing 20131019 (19/31) ---\n",
      "Processing transit data for date: 20131019\n",
      "1. Loading GTFS data...\n",
      "✗ Failed to process 20131019: [Errno 2] No such file or directory: '../data/raw/20131019\\\\routes.txt'\n",
      "\n",
      "--- Processing 20131020 (20/31) ---\n",
      "Processing transit data for date: 20131020\n",
      "1. Loading GTFS data...\n",
      "✗ Failed to process 20131020: [Errno 2] No such file or directory: '../data/raw/20131020\\\\routes.txt'\n",
      "\n",
      "--- Processing 20131021 (21/31) ---\n",
      "Processing transit data for date: 20131021\n",
      "1. Loading GTFS data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Documents\\Projects\\budapest_time_travel\\src\\data_processor\\data_loader.py:25: DtypeWarning: Columns (0,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  trips_df = pd.read_csv(trips_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. Loading existing processed data...\n",
      "3. Building service date mappings...\n",
      "4. Processing routes...\n",
      "No duplicate route_id found in routes_df.\n",
      "5. Processing route versions...\n",
      "6. Processing shape variants...\n",
      "Removed 8899 duplicate rows where only exception_type differed (NaN vs non-NaN).\n",
      "return_df:  Index(['version_id', 'route_id', 'direction_id', 'is_main', 'shape_id',\n",
      "       'trip_headsign', 'date', 'exception_type'],\n",
      "      dtype='object')\n",
      "Updated shape_variants_df:\n",
      "Shape: (1178, 6)\n",
      "\n",
      "Updated shape_variant_activations_df:\n",
      "Shape: (43932, 3)\n",
      "\n",
      "Summary:\n",
      "Total unique shape variants: 1178\n",
      "Total shape variant activations: 43932\n",
      "New variants added: 27\n",
      "Shape variant IDs added: 101151 - 101177\n",
      "New activations added: 5178\n",
      "7. Updating shapes data...\n",
      "\n",
      "=== Before update Shapes Summary ===\n",
      "Total shape records: 210,973\n",
      "Unique shapes: 1,151\n",
      "Average points per shape: 183.3\n",
      "Points per shape range: 6 - 957\n",
      "Found 8 missing shape_ids that need to be added.\n",
      "Found 8 missing shape_ids in shapes_df.\n",
      "Missing shape_ids: ['E010', 'L673', 'R263', 'R264', 'T097', 'T098', 'X351', 'X352']\n",
      "Added 1234 shape records to shapes_df.\n",
      "New shapes_df shape: (212207, 6)\n",
      "\n",
      "=== After update Shapes Summary ===\n",
      "Total shape records: 212,207\n",
      "Unique shapes: 1,159\n",
      "Average points per shape: 183.09\n",
      "Points per shape range: 6 - 957\n",
      "8. Saving processed data...\n",
      "shapes_df saved to ../data/processed/shapes.csv\n",
      "routes_df saved to ../data/processed/routes.csv\n",
      "route_versions_df saved to ../data/processed/route_versions.csv\n",
      "shape_variants_df saved to ../data/processed/shape_variants.csv\n",
      "shape_variant_activations_df saved to ../data/processed/shape_variant_activations.csv\n",
      "Processing completed successfully!\n",
      "✓ Successfully processed 20131021\n",
      "\n",
      "--- Processing 20131022 (22/31) ---\n",
      "Processing transit data for date: 20131022\n",
      "1. Loading GTFS data...\n",
      "✗ Failed to process 20131022: [Errno 2] No such file or directory: '../data/raw/20131022\\\\routes.txt'\n",
      "\n",
      "--- Processing 20131023 (23/31) ---\n",
      "Processing transit data for date: 20131023\n",
      "1. Loading GTFS data...\n",
      "✗ Failed to process 20131023: [Errno 2] No such file or directory: '../data/raw/20131023\\\\routes.txt'\n",
      "\n",
      "--- Processing 20131024 (24/31) ---\n",
      "Processing transit data for date: 20131024\n",
      "1. Loading GTFS data...\n",
      "✗ Failed to process 20131024: [Errno 2] No such file or directory: '../data/raw/20131024\\\\routes.txt'\n",
      "\n",
      "--- Processing 20131025 (25/31) ---\n",
      "Processing transit data for date: 20131025\n",
      "1. Loading GTFS data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Documents\\Projects\\budapest_time_travel\\src\\data_processor\\data_loader.py:25: DtypeWarning: Columns (0,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  trips_df = pd.read_csv(trips_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. Loading existing processed data...\n",
      "3. Building service date mappings...\n",
      "4. Processing routes...\n",
      "No duplicate route_id found in routes_df.\n",
      "5. Processing route versions...\n",
      "6. Processing shape variants...\n",
      "Removed 10729 duplicate rows where only exception_type differed (NaN vs non-NaN).\n",
      "return_df:  Index(['version_id', 'route_id', 'direction_id', 'is_main', 'shape_id',\n",
      "       'trip_headsign', 'date', 'exception_type'],\n",
      "      dtype='object')\n",
      "Updated shape_variants_df:\n",
      "Shape: (1249, 6)\n",
      "\n",
      "Updated shape_variant_activations_df:\n",
      "Shape: (51223, 3)\n",
      "\n",
      "Summary:\n",
      "Total unique shape variants: 1249\n",
      "Total shape variant activations: 51223\n",
      "New variants added: 71\n",
      "Shape variant IDs added: 101178 - 101248\n",
      "New activations added: 7291\n",
      "7. Updating shapes data...\n",
      "\n",
      "=== Before update Shapes Summary ===\n",
      "Total shape records: 212,207\n",
      "Unique shapes: 1,159\n",
      "Average points per shape: 183.09\n",
      "Points per shape range: 6 - 957\n",
      "Found 44 missing shape_ids that need to be added.\n",
      "Found 44 missing shape_ids in shapes_df.\n",
      "Missing shape_ids: ['E516', 'E517', 'I372', 'K646', 'K795', 'K796', 'N319', 'N323', 'N874', 'N941', 'P912', 'R858', 'R859', 'R860', 'R861', 'S960', 'S961', 'T099', 'T100', 'T101', 'T102', 'T110', 'T111', 'T112', 'T116', 'T117', 'T686', 'U496', 'V375', 'V376', 'W965', 'W967', 'X053', 'X054', 'X097', 'X534', 'X535', 'X538', 'X571', 'X573', 'X574', 'X575', 'X647', 'X648']\n",
      "Added 7288 shape records to shapes_df.\n",
      "New shapes_df shape: (219495, 6)\n",
      "\n",
      "=== After update Shapes Summary ===\n",
      "Total shape records: 219,495\n",
      "Unique shapes: 1,203\n",
      "Average points per shape: 182.46\n",
      "Points per shape range: 6 - 957\n",
      "8. Saving processed data...\n",
      "shapes_df saved to ../data/processed/shapes.csv\n",
      "routes_df saved to ../data/processed/routes.csv\n",
      "route_versions_df saved to ../data/processed/route_versions.csv\n",
      "shape_variants_df saved to ../data/processed/shape_variants.csv\n",
      "shape_variant_activations_df saved to ../data/processed/shape_variant_activations.csv\n",
      "Processing completed successfully!\n",
      "✓ Successfully processed 20131025\n",
      "\n",
      "--- Processing 20131026 (26/31) ---\n",
      "Processing transit data for date: 20131026\n",
      "1. Loading GTFS data...\n",
      "✗ Failed to process 20131026: [Errno 2] No such file or directory: '../data/raw/20131026\\\\routes.txt'\n",
      "\n",
      "--- Processing 20131027 (27/31) ---\n",
      "Processing transit data for date: 20131027\n",
      "1. Loading GTFS data...\n",
      "✗ Failed to process 20131027: [Errno 2] No such file or directory: '../data/raw/20131027\\\\routes.txt'\n",
      "\n",
      "--- Processing 20131028 (28/31) ---\n",
      "Processing transit data for date: 20131028\n",
      "1. Loading GTFS data...\n",
      "✗ Failed to process 20131028: [Errno 2] No such file or directory: '../data/raw/20131028\\\\routes.txt'\n",
      "\n",
      "--- Processing 20131029 (29/31) ---\n",
      "Processing transit data for date: 20131029\n",
      "1. Loading GTFS data...\n",
      "✗ Failed to process 20131029: [Errno 2] No such file or directory: '../data/raw/20131029\\\\routes.txt'\n",
      "\n",
      "--- Processing 20131030 (30/31) ---\n",
      "Processing transit data for date: 20131030\n",
      "1. Loading GTFS data...\n",
      "✗ Failed to process 20131030: [Errno 2] No such file or directory: '../data/raw/20131030\\\\routes.txt'\n",
      "\n",
      "--- Processing 20131031 (31/31) ---\n",
      "Processing transit data for date: 20131031\n",
      "1. Loading GTFS data...\n",
      "✗ Failed to process 20131031: [Errno 2] No such file or directory: '../data/raw/20131031\\\\routes.txt'\n",
      "\n",
      "=== PROCESSING SUMMARY ===\n",
      "Total dates: 31\n",
      "Successful: 3\n",
      "Failed: 28\n",
      "Failed dates: ['20131001', '20131002', '20131003', '20131004', '20131005', '20131006', '20131007', '20131008', '20131009', '20131010', '20131011', '20131012', '20131013', '20131014', '20131015', '20131016', '20131017', '20131019', '20131020', '20131022', '20131023', '20131024', '20131026', '20131027', '20131028', '20131029', '20131030', '20131031']\n"
     ]
    }
   ],
   "source": [
    "from data_processor import FlexibleDateProcessor\n",
    "processor = FlexibleDateProcessor('../data/processed/')\n",
    "\n",
    "# # Process just one date (your folder name)\n",
    "# processor.process_dates('20131018')\n",
    "\n",
    "# # Process a week of data\n",
    "# processor.process_dates({'start': '20131018', 'days': 7})\n",
    "\n",
    "# Process a specific month\n",
    "processing_result = processor.process_dates({'start': '20131001', 'end': '20131031'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c5782ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['shapes', 'routes', 'route_versions', 'shape_variants', 'shape_variant_activations', 'temporary_changes', 'latest_routes', 'shape_variant_data'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processing_result[\"20131018\"][\"data\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ce3f1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "budapest_tt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
